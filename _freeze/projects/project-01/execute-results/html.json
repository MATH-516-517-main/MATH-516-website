{
  "hash": "869959aade4764a8c8ab7ecd86530bc3",
  "result": {
    "markdown": "---\ntitle: \"Project 1\"\nsubtitle: \"Snow Particles\"\nbibliography: ref.bib\nurlcolor: blue\n---\n\n\n\n::: callout-important\n**Due date:** Sunday, March 3\n:::\n\n::: {.callout-note collapse=\"true\"}\n# Invite link for GitHub Classroom\n\nUse the corresponding invite link in [this google doc](https://docs.google.com/document/d/12aVHO4med_qwvEkPE7KHtq1Tme0IVEXgEdLGZStvBco/edit?usp=sharing) (accessible with your EPFL account) to accept the project, and either join an existing team or create a new one. Once this is done, go to the [course GitHub organization](https://github.com/MATH-516) and locate the repo titled `project-TEAM-NAME` to get started.\n:::\n\n::: {.callout-warning collapse=\"true\"}\n# Submission requirements\n\nYou are required to hand in a PDF version of your report `report.pdf` (generated from the quarto file `report.qmd`, if applicable) and the quarto file itself. The `report.qmd` should contain all the code necessary to reproduce your results: you should not show the actual code in the PDF report, unless you want to point out something specific.\n\nYour `README.md` should contain instructions on reproducing the PDF report from the quarto file. This can be useful if you have issues with the automatic generation of the PDF report right before the deadline.\n\nAn aternative to quarto (or Rmarkdown), is to use LaTeX to produce the report. In that case, you will also need to submit the source code where chunks should be well commented and references to the figures in the report should be clear.\n\n**Checklist**:\n\n1. [ ] `report.pdf` in GitHub repository (**max 15 pages**)\n2. [ ]  Source code in GitHub repository \n3. [ ] `README.md` with instructions on how to run the code and reproduce the PDF report\n:::\n\n::: {.callout-note collapse=\"true\"}\n# Description of the Project\n\n\n\n\n\n## Data\n\n-   data from a (former) PhD student at the Laboratory of Cryospheric Sciences at EPFL, essentially snow-flake diameters\n    -   shared with the permision of the authors of [this paper](https://www.sciencedirect.com/science/article/pii/S1875963717301246)\n-   the total number of particles measured (variable `particles.detected`) and the fraction (variable `retained [%]`) of particles belonging to each diameter bin (given by `startpoint` and `endpoint`)\n    -   only binned data are available (and the grid is not equidistant)\n\n\\footnotesize\n\n![](/images/snow_snap.png){width=40%}\n\n\\normalsize\n\n## The Goal\n\nSimulate diameters from a distribution, which is as close as possible to the observed data, in order to study aeolian transport of snow using certain numerical models\n\n-   i.e., the goal is to do Monte Carlo: **how to simulate snow-flake diameters that are compatible with the data?**\n\nExpert knowledge: a mixture of two log-normal distributions is a good model for the diameters\n\n## Tasks for You\n\n1.  Is the assumption viable, i.e. is bi-log-normal distribution a reasonable model for the data?\n    -   simple exploration of the data\n2.  Fit the bi-log-normal distribution in order to be able to simulate the data easily\n    -   jittering and EM algorithm\n    -   optimization (e.g. local search starting from the jittered EM result)\n    -   Bayesian approach\n3.  Test whether the diameters come from a bi-log-normal distribution\n    -   parametric Bootstrap and goodness of fit\n\n## MATH-517 Content\n\n-   Week 1: Introduction & Software & Data Considerations\n-   Week 2: Graphics & Visualization\n-   **Week 3: Kernel Density Estimation**\n-   Week 4: Non-parametric Regression\n-   **Week 5: Cross-validation**\n-   **Week 6: EM Algorithm**\n-   **Week 7: EM Algorithm**\n-   **Week 8: Monte Carlo**\n-   **Week 9: Bootstrap**\n-   **Week 10: Bootstrap**\n-   **Week 11: Bayesian Computations**\n-   **Week 12: Bayesian Computations**\n-   Week 13: Decision Trees\n-   Week 14: $\\emptyset$\n    -   Weeks in bold are pertinent to Project 1\n    -   Weeks 1-2 established the workflow needed for all the projects\n\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}